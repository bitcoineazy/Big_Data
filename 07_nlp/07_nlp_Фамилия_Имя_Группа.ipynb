{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы:\n",
    "* Макрушин С.В. Лекция \"Введение в обработку текста на естественном языке\"\n",
    "* https://www.nltk.org/api/nltk.metrics.distance.html\n",
    "* https://pymorphy2.readthedocs.io/en/stable/user/guide.html\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/noble6/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. При помощи расстояния Левенштейна иправьте опечатку в слове \"велечайшим\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки второго задания на слова. Проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Разбейте текст из формулировки второго задания на слова. Проведите стемминг и лемматизацию слов.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 2 в векторы при помощи `CountVectorizer`. Выведите на экран словарь обученного токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Разбейте текст из формулировки второго задания на слова. Проведите стемминг и лемматизацию слов.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Загрузите данные из файла `ru_recipes_sample.csv` в виде `pd.DataFrame` `recipes` Используя регулярные выражения, удалите из описаний (столбец `description`) все символы, кроме русских букв, цифр и пробелов. Приведите все слова в описании к нижнему регистру. Сохраните полученный результат в столбец `description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       этот коктейль готовлю из замороженной клубники...\n",
       "1                                         быстро и вкусно\n",
       "2                сытный овощной салатик пальчики оближете\n",
       "3       картофельное пюре и куриные котлеты  вкусная к...\n",
       "4       вишневая наливка имеет яркий вишневый вкус кот...\n",
       "                              ...                        \n",
       "3462    для тех кто любит чечевицу вам сюда очень вкус...\n",
       "3463    баклажановые фантазии продолжаются предлагаю в...\n",
       "3464    мое любимое блюдо лазанья но кушать только фар...\n",
       "3465    прошлым летом варила варенье из одуванчиков по...\n",
       "3466     и три корочки хлеба  сделал заказ буратино в ...\n",
       "Name: description, Length: 3467, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "recipes = pd.read_csv(\"07_nlp_data/ru_recipes_sample.csv\")\n",
    "\n",
    "#recipes[\"description\"] = recipes[\"description\"].apply(lambda x: x if re.search(r\"\\w\\w\", x) else None)\n",
    "recipes[\"description\"] = recipes[\"description\"].replace(to_replace=r\"[^А-Яа-яЁё0-9\\s]\", value=\"\", regex=True)\n",
    "recipes[\"description\"] = recipes[\"description\"].apply(lambda x: x.lower())\n",
    "\n",
    "recipes[\"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние Левенштейна. Выведите на экран результат в следующем виде:\n",
    "\n",
    "```\n",
    "d(word1, word2) = x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['серым',\n",
       " 'светланка',\n",
       " 'осталась',\n",
       " 'случиться',\n",
       " 'овсяными',\n",
       " 'острой',\n",
       " 'догадается',\n",
       " 'ошеломительным',\n",
       " 'великолепно',\n",
       " 'девиз']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = list(set(nltk.word_tokenize(\" \".join(recipes['description']).replace('\\r', ' ').replace('\\n', ' '))))\n",
    "\n",
    "unique_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(горячего, готовке) = 6\n",
      "d(ямальская, кушать) = 8\n",
      "d(мечта, запомню) = 7\n",
      "d(разлетелись, фальшивыми) = 9\n",
      "d(вашей, представителя) = 11\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_words = random.sample(unique_words, k=10)\n",
    "\n",
    "for i in range(0, len(random_words) - 1, 2):\n",
    "    print(f\"d({random_words[i]}, {random_words[i+1]}) = {nltk.edit_distance(random_words[i], random_words[i+1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Напишите функцию, которая принимает на вход 2 текстовые строки `s1` и `s2` и при помощи расстояния Левенштейна определяет, является ли строка `s2` плагиатом `s1`. Функция должна реализовывать следующую логику: для каждого слова `w1` из `s1` проверяет, есть в `s2` хотя бы одно слово `w2`, такое, что расстояние Левенштейна между `w1` и `w2` меньше 2, и считает количество таких слов в `s1` $P$. \n",
    "\n",
    "$$ P = \\#\\{w_1 \\in s_1\\ | \\exists w_2 \\in s_2 : d(w_1, w_2) < tol\\}$$\n",
    "\n",
    "$$ L = max(|s1|, |s2|) $$\n",
    "\n",
    "Здесь $|\\cdot|$ - количество слов в строке, $\\#A$ - число элементов в множестве $A$, $w \\in s$ означает, что слово $w$ содержится в тексте $s$.\n",
    "\n",
    "Если отношение $P / L$ больше 0.8, то функция должна вернуть True; иначе False.\n",
    "\n",
    "Продемонстрируйте работу вашей функции на примере описаний двух рецептов с ID 135488 и 851934 (ID рецепта - это число, стоящее в конце url рецепта). Выведите на экран описания этих рецептов и результат работы функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plagiarism(s1: str, s2: str) -> bool:\n",
    "    s1 = word_tokenize(s1)\n",
    "    s2 = word_tokenize(s2)\n",
    "    L = max(len(s1), len(s2))\n",
    "    P = 0\n",
    "    for word in s1:\n",
    "        for word_2 in s2:\n",
    "            if nltk.edit_distance(word, word_2) < 2:\n",
    "                P += 1\n",
    "    # print(P / L)\n",
    "    return (P / L) > 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>https://www.povarenok.ru/recipes/show/135488/</td>\n",
       "      <td>Паштет сало-авокадо в хлебных орешках</td>\n",
       "      <td>{'Сало': '100 г', 'Соль': '1/3 ч. л.', 'Чеснок...</td>\n",
       "      <td>прекрасной закуской к крепким напиткам на фурш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>https://www.povarenok.ru/recipes/show/851934/</td>\n",
       "      <td>Паштет из сала и авокадов хлебных орешках</td>\n",
       "      <td>{'Сало': '100 г', 'Соль': '1/3 ч. л.', 'Чеснок...</td>\n",
       "      <td>замечательной закуской к напиткам на фуршетном...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url  \\\n",
       "958   https://www.povarenok.ru/recipes/show/135488/   \n",
       "1473  https://www.povarenok.ru/recipes/show/851934/   \n",
       "\n",
       "                                           name  \\\n",
       "958       Паштет сало-авокадо в хлебных орешках   \n",
       "1473  Паштет из сала и авокадов хлебных орешках   \n",
       "\n",
       "                                            ingredients  \\\n",
       "958   {'Сало': '100 г', 'Соль': '1/3 ч. л.', 'Чеснок...   \n",
       "1473  {'Сало': '100 г', 'Соль': '1/3 ч. л.', 'Чеснок...   \n",
       "\n",
       "                                            description  \n",
       "958   прекрасной закуской к крепким напиткам на фурш...  \n",
       "1473  замечательной закуской к напиткам на фуршетном...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рецепты с нужным нам ID\n",
    "\n",
    "recipes[(recipes[\"url\"].str.endswith(\"851934/\")) | (recipes[\"url\"].str.endswith(\"135488/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plagiarism(recipes[recipes[\"url\"].str.endswith(\"135488/\")][\"description\"].values[0], recipes[recipes[\"url\"].str.endswith(\"851934/\")][\"description\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. На основе набора слов из задания 2 создайте `pd.DataFrame` со столбцами `word`, `stemmed_word` и `normalized_word`. В столбец `stemmed_word` поместите версию слова после проведения процедуры стемминга; в столбец `normalized_word` поместите версию слова после проведения процедуры лемматизации. Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга можно воспользоваться `SnowballStemmer` из `nltk`, для лемматизации слов - пакетом `pymorphy2`. Сравните результаты стемминга и лемматизации. Поясните на примере одной из строк получившегося фрейма (в виде текстового комментария), в чем разница между двумя этими подходами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>серым</th>\n",
       "      <td>сер</td>\n",
       "      <td>серый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>светланка</th>\n",
       "      <td>светланк</td>\n",
       "      <td>светланка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>осталась</th>\n",
       "      <td>оста</td>\n",
       "      <td>остаться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>случиться</th>\n",
       "      <td>случ</td>\n",
       "      <td>случиться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>овсяными</th>\n",
       "      <td>овсян</td>\n",
       "      <td>овсяный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>консистенцией</th>\n",
       "      <td>консистенц</td>\n",
       "      <td>консистенция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>фунчозы</th>\n",
       "      <td>фунчоз</td>\n",
       "      <td>фунчоз</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>легкая</th>\n",
       "      <td>легк</td>\n",
       "      <td>лёгкий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>никакой</th>\n",
       "      <td>никак</td>\n",
       "      <td>никакой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>порционно</th>\n",
       "      <td>порцион</td>\n",
       "      <td>порционный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16451 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              stemmed_word normalized_word\n",
       "word                                      \n",
       "серым                  сер           серый\n",
       "светланка         светланк       светланка\n",
       "осталась              оста        остаться\n",
       "случиться             случ       случиться\n",
       "овсяными             овсян         овсяный\n",
       "...                    ...             ...\n",
       "консистенцией   консистенц    консистенция\n",
       "фунчозы             фунчоз          фунчоз\n",
       "легкая                легк          лёгкий\n",
       "никакой              никак         никакой\n",
       "порционно          порцион      порционный\n",
       "\n",
       "[16451 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "stem_lem_df = pd.DataFrame(columns=['word', 'stemmed_word', 'normalized_word'])\n",
    "stem_lem_df['word'] = unique_words\n",
    "stem_lem_df['stemmed_word'] = [stemmer.stem(word) for word in stem_lem_df['word']]\n",
    "stem_lem_df['normalized_word'] = [morph.parse(word)[0].normalized.word for word in stem_lem_df['word']]\n",
    "stem_lem_df = stem_lem_df.set_index('word')\n",
    "stem_lem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Добавьте в таблицу `recipes` столбец `description_no_stopwords`, в котором содержится текст описания рецепта после удаления из него стоп-слов. Посчитайте и выведите на экран долю стоп-слов среди общего количества слов. Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/noble6/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_366420/1450924871.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  recipes['description_no_stopwords'] = recipes['description'].str.replace(pattern, '')\n"
     ]
    }
   ],
   "source": [
    "stops = stopwords.words('russian')\n",
    "pattern = r'\\b(?:{})\\b'.format('|'.join(stops))\n",
    "recipes['description_no_stopwords'] = recipes['description'].str.replace(pattern, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102978, 33223, 0.322622307677368)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "word_counts_before = Counter(word_tokenize(' '.join(recipes['description'])))\n",
    "count_before, count_stops = sum(word_counts_before.values()), sum([word_counts_before[x] for x in stops])\n",
    "count_before, count_stops, count_stops / count_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69755, 69755)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_after = Counter(word_tokenize(' '.join(recipes['description_no_stopwords'])))\n",
    "word_count_before = word_counts_before.most_common(10)\n",
    "word_count_after = word_counts_after.most_common(10)\n",
    "sum(word_counts_after.values()), count_before - count_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 5054),\n",
       " ('в', 2584),\n",
       " ('с', 1934),\n",
       " ('на', 1655),\n",
       " ('очень', 1607),\n",
       " ('не', 1517),\n",
       " ('из', 1006),\n",
       " ('я', 979),\n",
       " ('рецепт', 869),\n",
       " ('а', 863)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('очень', 1607),\n",
       " ('рецепт', 869),\n",
       " ('это', 734),\n",
       " ('блюдо', 524),\n",
       " ('вкусный', 461),\n",
       " ('просто', 436),\n",
       " ('вкусно', 375),\n",
       " ('приготовить', 344),\n",
       " ('вкус', 324),\n",
       " ('салат', 313)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Выберите случайным образом 5 рецептов из набора данных, в названии которых есть слово \"оладьи\" (без учета регистра). Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`. На основе полученных векторов создайте `pd.DataFrame`, в котором названия колонок соответствуют словам из словаря объекта-векторизатора. \n",
    "\n",
    "Примечание: обратите внимание на порядок слов при создании колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>супер</th>\n",
       "      <th>быстрый</th>\n",
       "      <th>вариант</th>\n",
       "      <th>завтрака</th>\n",
       "      <th>это</th>\n",
       "      <th>даже</th>\n",
       "      <th>быстрее</th>\n",
       "      <th>чем</th>\n",
       "      <th>сварить</th>\n",
       "      <th>овсянку</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      супер   быстрый   вариант  завтрака       это      даже   быстрее  \\\n",
       "0  0.316228  0.316228  0.316228  0.316228  0.316228  0.316228  0.316228   \n",
       "\n",
       "        чем   сварить   овсянку  \n",
       "0  0.316228  0.316228  0.316228  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "olad = recipes[recipes['name'].str.contains('оладьи')]\n",
    "sample = olad.sample(n=5)\n",
    "sample\n",
    "\n",
    "def get_dataframe_vect(sent_words):\n",
    "    cv = TfidfVectorizer()\n",
    "    cv.fit(sent_words)\n",
    "    return pd.DataFrame([{elem: cv.transform(sent_words).toarray()[0][cv.vocabulary_[elem]] for elem in cv.vocabulary_}])\n",
    "\n",
    "get_dataframe_vect(nltk.sent_tokenize(sample['description'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Вычислите близость между каждой парой рецептов, выбранных в задании 6, используя косинусное расстояние (можно воспользоваться функциями из любого пакета: `scipy`, `scikit-learn` или реализовать функцию самому). Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов.\n",
    "\n",
    "Примечание: обратите внимание, что $d_{cosine}(x, x) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.03834825],\n",
       "       [0.        , 1.        , 0.09682458, 0.06804138, 0.07426107],\n",
       "       [0.        , 0.09682458, 1.        , 0.08784105, 0.05752237],\n",
       "       [0.        , 0.06804138, 0.08784105, 1.        , 0.17516462],\n",
       "       [0.03834825, 0.07426107, 0.05752237, 0.17516462, 1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "random_descriptions = [sample.iloc[i]['description'] for i in range(5)]\n",
    "vectorizer_vector = CountVectorizer().fit_transform(random_descriptions).toarray()\n",
    "csim = cosine_similarity(vectorizer_vector)\n",
    "csim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Бананово-кукурузные оладьи</th>\n",
       "      <th>Картофельно-творожные оладьи</th>\n",
       "      <th>Картофельные оладьи с соусом \"Весна\"</th>\n",
       "      <th>Голландские лимонные оладьи</th>\n",
       "      <th>Куриные оладьи с сыром</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Бананово-кукурузные оладьи</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Картофельно-творожные оладьи</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.074261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Картофельные оладьи с соусом \"Весна\"</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.057522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Голландские лимонные оладьи</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Куриные оладьи с сыром</th>\n",
       "      <td>0.038348</td>\n",
       "      <td>0.074261</td>\n",
       "      <td>0.057522</td>\n",
       "      <td>0.175165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Бананово-кукурузные оладьи  \\\n",
       "Бананово-кукурузные оладьи                              0.000000   \n",
       "Картофельно-творожные оладьи                            0.000000   \n",
       "Картофельные оладьи с соусом \"Весна\"                    0.000000   \n",
       "Голландские лимонные оладьи                             0.000000   \n",
       "Куриные оладьи с сыром                                  0.038348   \n",
       "\n",
       "                                      Картофельно-творожные оладьи  \\\n",
       "Бананово-кукурузные оладьи                                0.000000   \n",
       "Картофельно-творожные оладьи                              0.000000   \n",
       "Картофельные оладьи с соусом \"Весна\"                      0.096825   \n",
       "Голландские лимонные оладьи                               0.068041   \n",
       "Куриные оладьи с сыром                                    0.074261   \n",
       "\n",
       "                                      Картофельные оладьи с соусом \"Весна\"  \\\n",
       "Бананово-кукурузные оладьи                                        0.000000   \n",
       "Картофельно-творожные оладьи                                      0.096825   \n",
       "Картофельные оладьи с соусом \"Весна\"                              0.000000   \n",
       "Голландские лимонные оладьи                                       0.087841   \n",
       "Куриные оладьи с сыром                                            0.057522   \n",
       "\n",
       "                                      Голландские лимонные оладьи  \\\n",
       "Бананово-кукурузные оладьи                               0.000000   \n",
       "Картофельно-творожные оладьи                             0.068041   \n",
       "Картофельные оладьи с соусом \"Весна\"                     0.087841   \n",
       "Голландские лимонные оладьи                              0.000000   \n",
       "Куриные оладьи с сыром                                   0.175165   \n",
       "\n",
       "                                      Куриные оладьи с сыром  \n",
       "Бананово-кукурузные оладьи                          0.038348  \n",
       "Картофельно-творожные оладьи                        0.074261  \n",
       "Картофельные оладьи с соусом \"Весна\"                0.057522  \n",
       "Голландские лимонные оладьи                         0.175165  \n",
       "Куриные оладьи с сыром                              0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(csim, columns=sample['name'].values, index=sample['name'].values)\n",
    "for i in range(5):\n",
    "    df.iloc[i][i] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напишите функцию, которая принимает на вход `pd.DataFrame`, полученный в задании 7, и возвращает в виде кортежа названия двух различных рецептов, которые являются наиболее похожими. Прокомментируйте результат (в виде текстового комментария). Для объяснения результата сравните слова в описаниях двух этих отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(sim_df: pd.DataFrame) -> tuple:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175164618081796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Голландские лимонные оладьи', 'Куриные оладьи с сыром')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest(sim_df: pd.DataFrame) -> tuple:\n",
    "    print(sim_df[sim_df == sim_df.max().max()].stack().values[0])\n",
    "    return sim_df[sim_df == sim_df.max().max()].stack().index.tolist()[0]\n",
    "find_closest(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175164618081796\n",
      "  голландские оладьи особенность которых заключается в чуть более шарообразной форме в отличие от наших пышных но просто круглых оладий готовятся очень быстро с использованием дрожжей обжариваются на сковороде как на специальной с углублениями так и на совершенно обыкновенной рецепт который я нашла интересен наличием лимонного сока в тесте который придает оладушкам желтый оттенок и тем что при приготовлении требуется совсем небольшое количество сахара есть повод достать мед варенье шоколадный сироп и подавать голландские оладьи к завтраку с чемто таким сладким\n",
      "0.175164618081796\n",
      "лет двадцать назад покупая сыр наткнулась на рекламный листок к этому сыру и внутри был рецепт оладьев с простым составом и соотношением продуктов решила попробовать и в результате вот уже много лет это любимое блюдо которое потом разошлось по всем родственникам и друзьям оладушки получаются очень нежными с пикантным вкусом хороши как с пылужару так и холодными на бутерброд\n",
      "все ингредиенты указаны на 500 грамм фарша я готовила в три раза больше\n"
     ]
    }
   ],
   "source": [
    "# Оладьи\n",
    "print(sample[sample['name'] == find_closest(df)[0]]['description'].values[0])\n",
    "print(sample[sample['name'] == find_closest(df)[1]]['description'].values[0])\n",
    "\n",
    "# Расстояние - 17%, оба рецепта оладьи"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
